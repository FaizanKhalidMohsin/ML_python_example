{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS 803 / CP 8318 Assignment 2\n",
    "## CPS 803 [30 Marks]\n",
    "## CP 8318 [36 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# You may need some sklearn specific imports, or other standard toolboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.,  80.,  82., ...,   0.,   0.,   0.],\n",
       "       [151., 150., 147., ...,   0.,   0.,   0.],\n",
       "       [231., 212., 156., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [ 74.,  81.,  87., ...,   1.,   0.,   0.],\n",
       "       [222., 227., 203., ...,   0.,   0.,   0.],\n",
       "       [195., 199., 205., ...,   1.,   0.,   0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingset = np.loadtxt('training.csv', delimiter=',')\n",
    "testingset = np.loadtxt('test.csv', delimiter=',')\n",
    "\n",
    "trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2304 # images are 48 x 48\n",
    "n_classes = 7 # 7 classes - as defined below\n",
    "img_dim = 48 # each input image dimension, width and height are both 48\n",
    "\n",
    "x_training = trainingset[:, 0:n_inputs] # Extract the first 2304 elements - the image\n",
    "y_training = trainingset[:, n_inputs:n_inputs + n_classes] # Extract the last 7 elements - a one hot category encoding\n",
    "\n",
    "x_testing = testingset[:, 0:n_inputs] # Extract the first 2304 elements - the image\n",
    "y_testing = testingset[:, n_inputs:n_inputs + n_classes] # Extract the last 7 elements - a one hot category encoding\n",
    "\n",
    "x_training = x_training.reshape(x_training.shape[0], 48, 48) # Make samples image shaped\n",
    "x_testing = x_testing.reshape(x_testing.shape[0], 48, 48) # Make samples image shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(whichemotion):\n",
    "    if whichemotion.shape[0] == 1:\n",
    "        indx = whichemotion[0]\n",
    "    else:\n",
    "        indx = np.argmax(whichemotion)\n",
    "    if indx == 0:\n",
    "        return 'angry'\n",
    "    elif indx == 1:\n",
    "        return 'disgust'\n",
    "    elif indx == 2:\n",
    "        return 'fear'\n",
    "    elif indx == 3:\n",
    "        return 'happy'\n",
    "    elif indx == 4:\n",
    "        return 'sad'\n",
    "    elif indx == 5:\n",
    "        return 'surprise'\n",
    "    elif indx == 6:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48)\n",
      "(28709, 7)\n",
      "(3589, 48, 48)\n",
      "(3589, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facial emotion: surprise\n"
     ]
    }
   ],
   "source": [
    "print(x_training.shape)\n",
    "print(y_training.shape)\n",
    "\n",
    "print(x_testing.shape)\n",
    "print(y_testing.shape)\n",
    "\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = x_training[sampleindex, :]\n",
    "sample = sample.reshape(48, 48)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print('facial emotion: %s' % get_emotion(y_training[sampleindex, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I : Happy or Sad\n",
    "\n",
    "## For this part you will consider a binary classification problem - categorizing faces as happy or sad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[1 Mark] a. Sample from the data loaded above to include only the happy or sad cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48)\n",
      "<class 'numpy.ndarray'>\n",
      "[[42. 43. 46. ... 28. 26. 26.]\n",
      " [40. 41. 43. ... 28. 26. 26.]\n",
      " [41. 42. 42. ... 28. 26. 26.]\n",
      " ...\n",
      " [13. 11. 10. ... 23. 24. 22.]\n",
      " [11. 10. 10. ... 21. 22. 20.]\n",
      " [10. 10. 10. ... 21. 19. 19.]]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(sample.shape)\n",
    "print(type(sample))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_testing[0:4, 4:6])\n",
    "print(y_testing[0:4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_testing_happy_sad_array.shape\n",
      "(3589, 2)\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_testing_happy_sad_array = y_testing[:, 4:6]\n",
    "print(\"y_testing_happy_sad_array.shape\")\n",
    "print(y_testing_happy_sad_array.shape)\n",
    "print(y_testing_happy_sad_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [ True False]\n",
      " ...\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "y_testing_happy_sad_array_index = y_testing_happy_sad_array == 1\n",
    "print(y_testing_happy_sad_array_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starts from here for choosing only happy and sad observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48)\n",
      "(28709, 7)\n",
      "(3589, 48, 48)\n",
      "(3589, 7)\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 1. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "y_testing_happy.shape\n",
      "(3589,)\n",
      "[0. 0. 1. 0.]\n",
      "y_testing_sad.shape\n",
      "(3589,)\n",
      "[0. 0. 0. 0.]\n",
      "show boolen vectors\n",
      "[False False False ... False False False]\n",
      "[False False  True ...  True  True  True]\n",
      "show happy sad boolen vector\n",
      "y_testing_happy_sad_index [False False  True ...  True  True  True]\n",
      "(3589,)\n",
      "y_training_happy_sad_index [False False False ...  True False  True]\n",
      "(28709,)\n"
     ]
    }
   ],
   "source": [
    "print(x_training.shape)\n",
    "print(y_training.shape)\n",
    "\n",
    "print(x_testing.shape)\n",
    "print(y_testing.shape)\n",
    "print(y_testing[0:4, :])\n",
    "\n",
    "print(y_testing[0:4, 0])\n",
    "print(y_testing[0:4, 4])\n",
    "print(y_testing[0:4, 5])\n",
    "y_testing_happy = y_testing[:, 4]\n",
    "y_training_happy = y_training[:, 4]\n",
    "\n",
    "print(\"y_testing_happy.shape\")\n",
    "print(y_testing_happy.shape)\n",
    "print(y_testing_happy[0:4])\n",
    "\n",
    "y_testing_sad = y_testing[:, 5]\n",
    "y_training_sad = y_training[:, 5]\n",
    "print(\"y_testing_sad.shape\")\n",
    "print(y_testing_sad.shape)\n",
    "print(y_testing_sad[0:4])\n",
    "#x_training\n",
    "\n",
    "# Extract Sad and happy people. \n",
    "y_testing_sad_index = y_testing_sad == 1\n",
    "y_testing_happy_index = y_testing_happy == 1\n",
    "\n",
    "print(\"show boolen vectors\")\n",
    "print(y_testing_sad_index)\n",
    "print(y_testing_happy_index)\n",
    "\n",
    "print(\"show happy sad boolen vector\")\n",
    "#print(testing_happy_sad_index)\n",
    "\n",
    "#print(y_testing_sad_index | y_testing_happy_index)\n",
    "y_testing_happy_sad_index = y_testing_sad_index | y_testing_happy_index\n",
    "print(\"y_testing_happy_sad_index\", y_testing_happy_sad_index)\n",
    "print(y_testing_happy_sad_index.shape)\n",
    "\n",
    "\n",
    "\n",
    "y_training_happy_sad_index = (y_training_sad == 1) | (y_training_happy == 1)\n",
    "print(\"y_training_happy_sad_index\", y_training_happy_sad_index)\n",
    "print(y_training_happy_sad_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589\n",
      "(28709, 48, 48)\n",
      "(28709, 7)\n",
      "(3589, 48, 48)\n",
      "(3589, 7)\n",
      "(8001, 48, 48)\n",
      "(8001, 2)\n",
      "(1068, 48, 48)\n",
      "(1068, 2)\n"
     ]
    }
   ],
   "source": [
    "# Using the happy_sad_index keep only the sad and happy X and Y data sets. \n",
    "print(len(happy_sad_index))\n",
    "print(x_training.shape)\n",
    "print(y_training.shape)\n",
    "\n",
    "print(x_testing.shape)\n",
    "print(y_testing.shape)\n",
    "\n",
    "\n",
    "x_training_happy_sad = x_training[y_training_happy_sad_index, : ]\n",
    "y_training_happy_sad = y_training[y_training_happy_sad_index, 4:6]\n",
    "\n",
    "x_testing_happy_sad = x_testing[y_testing_happy_sad_index, :]\n",
    "y_testing_happy_sad = y_testing[y_testing_happy_sad_index, 4:6]\n",
    "\n",
    "\n",
    "print(x_training_happy_sad.shape)\n",
    "print(y_training_happy_sad.shape)\n",
    "\n",
    "print(x_testing_happy_sad.shape)\n",
    "print(y_testing_happy_sad.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[4 Marks] b. Apply PCA and LDA to represent the faces, display a sample of a few faces for each case. You may consider using one or both of these in the steps that follow if they are of any value (this is for you to decide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-56a55f99e4ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Compute a PCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhiten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training_happy_sad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# apply PCA transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[1;32m--> 381\u001b[1;33m                         copy=self.copy)\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# Handle n_components==None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 570\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# PCA \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Compute a PCA \n",
    "n_components = 100\n",
    "pca = PCA(n_components=n_components, whiten=True).fit(x_training_happy_sad)\n",
    " \n",
    "# apply PCA transformation\n",
    "X_train_pca = pca.transform(x_training_happy_sad)\n",
    "X_test_pca = pca.transform(x_testing_happy_sady)\n",
    "\n",
    "\n",
    "# LDA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_train_PCA_LDA = lda.fit_transform(X_train_pca, y_training_happy_sad)\n",
    "X_test_PCA_LDA = lda.transform(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[2 Marks] c. Apply naive Bayes to classify faces as happy or sad. Report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[2 Marks] d. Apply Logistic regression to classify faces as happy or sad. Report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[2 Marks] e. Apply a Support Vector Machine to classify the faces as happy or sad. Choose parameters / arguments to try to maximize your accuracy. Report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 Mark] f. Which of the approaches above allow you to reliably determine the degree of happiness or sadness (i.e. how happy or how sad)? Which do you trust the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2 Marks] g. Based on your answer to f. show the 5 happiest faces and the 5 saddest faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II : Multi-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## For this part you will repeat the tasks in Part I, but instead consider the multi-class problem and classify inputs according to all 7 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4 Marks] a. Apply PCA and LDA to represent the faces, display a sample of a few faces for each case. Produce a plot for PCA showing the cumulative variance captured by adding additional principal components (e.g. 1st PC, 1st + 2nd PC, etc.). On the same figure, plot the same curve for only happy and sad faces used in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2 Marks] b. Classify the faces using Naive Bayes and report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of your classifier on the test set using a confusion matrix. Describe briefly how the multi-class nature of the problem is treated by the classifier.\n",
    "DESCRIBE BRIEFLY HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2 Marks] c. Classify the faces using logistic regression and report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of your classifier on the test set using a confusion matrix. Describe briefly how the multi-class nature of the problem is treated by the classifier.\n",
    "DESCRIBE BRIEFLY HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2 Marks] d. Classify the faces using a support vector machine and report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of your classifier on the test set using a confusion matrix. Describe briefly how the multi-class nature of the problem is treated by the classifier.\n",
    "DESCRIBE BRIEFLY HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2 Marks] e. Which categories of faces seem to be most similar or least similar?\n",
    "EXPLAIN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4 Marks] f. Let's assume that some of the faces were labeled wrong in producing the dataset. Propose and implement a solution that identifies images that are potentially mislabeled. Show 10 samples based on the method you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8318 only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the classification approaches considered above, choose one to score faces based on a continuous valued prediction of for each of the categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6 Marks] a. Produce a prediction for each face in the test set (this has 7 dimensions). Visualize these based on a 2D embedding of the scores. The \"data points\" plotted in the embedding should show the actual picture of the face, at the corresponding 2D point location. (You could consider using t-SNE for your embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
